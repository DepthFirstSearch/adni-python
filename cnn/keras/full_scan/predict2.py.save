##############################################################
# Set seed for determinisitc behaviour between different runs.
# Especially fresh weights will be initialized the same way.
# Caution: CudNN might not be deterministic after all.
SEED = 0
import numpy as np
np.random.seed(SEED)
##############################################################

from keras.optimizers import SGD
from cnn.keras.models.AVG444.model_normal import build_model
from utils.split_scans import read_imageID
from utils.sort_scans import sort_groups
import csv
import sys

fold = str(sys.argv[1])

# Training specific parameters
target_size = (22, 22, 22)
filter_length = 1
classes = ['MCI', 'AD']
batch_size =128
load_all_scans = True
# Paths
path_ADNI = '/home/mhubrich/ADNI_intnorm_avgpool444_new'
path_model = ['/home/mhubrich/checkpoints/adni/full_scan_23_CV1/model.0032-loss_0.852-acc_0.767-val_loss_0.4420-val_acc_0.8132-val_fmeasure_0.6600-val$


def predict():
    # Get inputs for training and validation
    scans_val = read_imageID(path_ADNI, '/home/mhubrich/ADNI_CV_MCI/' + fold + '_val')

    # Set up the model
    model = build_model()
    sgd = SGD(lr=0.001, decay=0.0005, momentum=0.9, nesterov=True)
    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])
    model.load_weights(path_model[int(fold)-1])

    nb_runs = ((target_size[0]-filter_length+1) ** 3) + 1
    nb_pred = len(scans_val) * nb_runs
    predictions = np.zeros((nb_pred, 1), dtype=np.float32)
    groups, _ = sort_groups(scans_val)
    scans = groups['MCI'] + groups['AD']
    i = 0
    for scan in scans:
        val_inputs = inputs(scan, target_size, batch_size, load_all_scans, classes, 'predict', SEED, 'binary', filter_length)
        val_inputs = ScanIterator()
        predictions[i:i+val_inputs.nb_sample] = model.predict_generator(val_inputs,
                                                                        val_inputs.nb_sample,
                                                                        max_q_size=batch_size,
                                                                        nb_worker=1,
                                                                        pickle_safe=True)
        i += val_inputs.nb_sample

    np.save('savefile_predictions_filter_' + str(filter_length) + '_CV' + fold + '.npy', predictions)
    with open('predictions_AVG444_fliter_' + str(filter_length) + '_CV' + fold + '.csv', 'wb') as csvfile:
        writer = csv.writer(csvfile)
        for i in range(len(scans)):
            for j in range(nb_runs):
                x, y, z = val_inputs.mod3(j, target_size[0] - filter_length + 1)
                writer.writerow([scans[i].imageID, str(x), str(y), str(z), str(predictions[i*nb_runs + j, 0])])


if __name__ == "__main__":
    predict()

